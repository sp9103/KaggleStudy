{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "np.random.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (5,8,10,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# trn = pd.read_csv('./dataset/train_ver2.csv')\n",
    "trn = pd.read_csv('./dataset/train_delete_empty_del.csv')\n",
    "tst = pd.read_csv('./dataset/test_ver2_del.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del trn['cod_prov'], trn['tipodom']\n",
    "# del tst['cod_prov'], tst['tipodom']\n",
    "\n",
    "# trn.to_csv('./dataset/train_delete_empty_del.csv', index=False)\n",
    "# tst.to_csv('./dataset/test_ver2_del.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dead = trn['indfall'] == 'S'\n",
    "# trn = trn[~dead]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn.to_csv('./dataset/train_delete_empty_del.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before tranin set shape :  (11066226, 46)\n"
     ]
    }
   ],
   "source": [
    "print('before tranin set shape : ', trn.shape)\n",
    "prods = trn.columns[24:].tolist()\n",
    "\n",
    "trn[prods] = trn[prods].fillna(0.0).astype(np.int8)\n",
    "\n",
    "# # if some customer buy anyting, remove\n",
    "# no_product = trn[prods].sum(axis=1) == 0\n",
    "# trn = trn[~no_product]\n",
    "# print('after tranin set shape : ', trn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for col in trn.columns[24:]:\n",
    "    tst[col] = 0\n",
    "\n",
    "df = pd.concat([trn, tst], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "# 범주형을 0, 1, 2와 같은 꼴로 변경시킴\n",
    "categorical_cols = ['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'nomprov', 'segmento']\n",
    "for col in categorical_cols:\n",
    "    df[col], _ = df[col].factorize(na_sentinel=-99)\n",
    "features += categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].replace(' NA', -99, inplace=True)\n",
    "df['age'] = df['age'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['antiguedad'].replace('     NA', -99, inplace=True)\n",
    "df['antiguedad'] = df['antiguedad'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['renta'].replace('         NA', -99, inplace=True)\n",
    "df['renta'].fillna(-99, inplace=True)\n",
    "df['renta'] = df['renta'].astype(float).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['indrel_1mes'].replace('P', 5, inplace=True)\n",
    "df['indrel_1mes'].fillna(-99, inplace=True)\n",
    "df['indrel_1mes'] = df['indrel_1mes'].astype(float).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += ['age','antiguedad','renta','ind_nuevo','indrel','indrel_1mes','ind_actividad_cliente']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ind_empleado',\n",
       " 'pais_residencia',\n",
       " 'sexo',\n",
       " 'tiprel_1mes',\n",
       " 'indresi',\n",
       " 'indext',\n",
       " 'conyuemp',\n",
       " 'canal_entrada',\n",
       " 'indfall',\n",
       " 'nomprov',\n",
       " 'segmento',\n",
       " 'age',\n",
       " 'antiguedad',\n",
       " 'renta',\n",
       " 'ind_nuevo',\n",
       " 'indrel',\n",
       " 'indrel_1mes',\n",
       " 'ind_actividad_cliente']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha_dato', 'ncodpers', 'ind_empleado', 'pais_residencia', 'sexo',\n",
       "       'age', 'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel',\n",
       "       'ult_fec_cli_1t', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext',\n",
       "       'conyuemp', 'canal_entrada', 'indfall', 'nomprov',\n",
       "       'ind_actividad_cliente', 'renta', 'segmento', 'ind_ahor_fin_ult1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.columns[:23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fecha_alta_month'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['fecha_alta_year'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['fecha_alta_month', 'fecha_alta_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ult_fec_cli_1t_month'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['ult_fec_cli_1t_year'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['ult_fec_cli_1t_month', 'ult_fec_cli_1t_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag_features = features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(-99, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>freq</th>\n",
       "      <th>top</th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ncodpers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15889</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15890</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15891</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15892</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15893</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15894</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15895</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15896</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15897</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15899</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15900</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15901</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15902</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15903</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15906</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15907</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15908</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15911</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15913</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15914</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15916</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15917</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15918</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15919</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15920</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15921</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15922</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15923</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15924</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15925</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553119</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553120</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553147</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553152</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553180</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553181</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553188</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553218</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553232</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553241</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553253</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553257</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553266</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553273</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553288</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553296</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553303</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553338</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553389</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553390</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553393</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553415</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553429</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553436</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553456</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553541</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553552</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553559</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553565</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553571</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731162 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         count freq top unique\n",
       "ncodpers                      \n",
       "15889       17   17   V      1\n",
       "15890       17   17   V      1\n",
       "15891        1    1   H      1\n",
       "15892       17   17   H      1\n",
       "15893       17   17   V      1\n",
       "15894       17   17   V      1\n",
       "15895       17   17   H      1\n",
       "15896       12   12   V      1\n",
       "15897       17   17   V      1\n",
       "15899       17   17   V      1\n",
       "15900       17   17   V      1\n",
       "15901       17   17   V      1\n",
       "15902       17   17   H      1\n",
       "15903       17   17   V      1\n",
       "15906       17   17   H      1\n",
       "15907       17   17   V      1\n",
       "15908       17   17   V      1\n",
       "15911       17   17   V      1\n",
       "15913       17   17   V      1\n",
       "15914       17   17   H      1\n",
       "15916       17   17   H      1\n",
       "15917       17   17   H      1\n",
       "15918       17   17   H      1\n",
       "15919       17   17   V      1\n",
       "15920       17   17   V      1\n",
       "15921       17   17   V      1\n",
       "15922       17   17   V      1\n",
       "15923       17   17   V      1\n",
       "15924       17   17   V      1\n",
       "15925       17   17   V      1\n",
       "...        ...  ...  ..    ...\n",
       "1553119      1    1   V      1\n",
       "1553120      1    1   H      1\n",
       "1553147      1    1   V      1\n",
       "1553152      1    1   H      1\n",
       "1553180      1    1   H      1\n",
       "1553181      1    1   H      1\n",
       "1553188      1    1   H      1\n",
       "1553218      1    1   H      1\n",
       "1553232      1    1   H      1\n",
       "1553241      1    1   H      1\n",
       "1553253      1    1   H      1\n",
       "1553257      1    1   H      1\n",
       "1553266      1    1   V      1\n",
       "1553273      1    1   V      1\n",
       "1553288      1    1   H      1\n",
       "1553296      1    1   H      1\n",
       "1553303      1    1   V      1\n",
       "1553338      1    1   H      1\n",
       "1553389      1    1   V      1\n",
       "1553390      1    1   H      1\n",
       "1553393      1    1   V      1\n",
       "1553415      1    1   V      1\n",
       "1553429      1    1   V      1\n",
       "1553436      1    1   V      1\n",
       "1553456      1    1   H      1\n",
       "1553541      1    1   V      1\n",
       "1553552      1    1   H      1\n",
       "1553559      1    1   H      1\n",
       "1553565      1    1   H      1\n",
       "1553571      1    1   V      1\n",
       "\n",
       "[731162 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in trn.groupby(['ncodpers'])['sexo']:\n",
    "#     sl = len(group['sexo'].unique())\n",
    "#     if sl != 1:\n",
    "#         print(i)\n",
    "#         print(sl)\n",
    "trn.groupby(['ncodpers'])['sexo'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_int(str_date):\n",
    "    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")] \n",
    "    int_date = (int(Y) - 2015) * 12 + int(M)\n",
    "    \n",
    "    return int_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['int_date'] = trn['fecha_dato'].map(date_to_int).astype(np.int8)\n",
    "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lag = df.copy()\n",
    "df_lag.columns = [col + '_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns ]\n",
    "df_lag['int_date'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "print(len(df_lag.columns))\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = df.merge(df_lag, on=['ncodpers','int_date'], how='left')\n",
    "del df, df_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    df_trn[prev].fillna(0, inplace=True)\n",
    "df_trn.fillna(-99, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += [feature + '_prev' for feature in features]\n",
    "features += [prod + '_prev' for prod in prods]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_dates = ['2016-01-28', '2016-02-28', '2016-03-28', '2016-04-28', '2016-05-28']\n",
    "trn = df_trn[df_trn['fecha_dato'].isin(use_dates)]\n",
    "tst = df_trn[df_trn['fecha_dato'] == '2016-06-28']\n",
    "del df_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i, prod in enumerate(prods):\n",
    "    prev = prod + '_prev'\n",
    "    #Extract new purchase\n",
    "    prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]\n",
    "    prY = np.zeros(prX.shape[0], dtype = np.int8) + i\n",
    "    X.append(prX)\n",
    "    Y.append(prY)\n",
    "XY = pd.concat(X)\n",
    "Y = np.hstack(Y)\n",
    "XY['y'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vld_date = '2016-05-28'\n",
    "XY_trn = XY[XY['fecha_dato'] != vld_date]\n",
    "XY_vld = XY[XY['fecha_dato'] == vld_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'booster' : 'gbtree',\n",
    "    'max_depth' : 8,\n",
    "    'nthread' : 8,\n",
    "    'num_class' : len(prods),\n",
    "    'objective' : 'multi:softprob',\n",
    "    'silent' : 1,\n",
    "    'eval_metric' : 'mlogloss',\n",
    "    'eta' : 0.1,\n",
    "    'min_child_weight' : 10,\n",
    "    'colsample_bytree' : 0.8,\n",
    "    'colsample_bylevel' : 0.9,\n",
    "    'seed': 2019,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_trn = XY_trn.as_matrix(columns=features)\n",
    "Y_trn = XY_trn.as_matrix(columns=['y'])\n",
    "dtrn = xgb.DMatrix(X_trn, label=Y_trn, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_vld = XY_vld.as_matrix(columns=features)\n",
    "Y_vld = XY_vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.66292\teval-mlogloss:2.67198\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:2.41947\teval-mlogloss:2.43226\n",
      "[2]\ttrain-mlogloss:2.24455\teval-mlogloss:2.25875\n",
      "[3]\ttrain-mlogloss:2.11228\teval-mlogloss:2.12801\n",
      "[4]\ttrain-mlogloss:2.0014\teval-mlogloss:2.01823\n",
      "[5]\ttrain-mlogloss:1.91338\teval-mlogloss:1.93156\n",
      "[6]\ttrain-mlogloss:1.83563\teval-mlogloss:1.85491\n",
      "[7]\ttrain-mlogloss:1.76611\teval-mlogloss:1.78566\n",
      "[8]\ttrain-mlogloss:1.70491\teval-mlogloss:1.72491\n",
      "[9]\ttrain-mlogloss:1.65473\teval-mlogloss:1.67533\n",
      "[10]\ttrain-mlogloss:1.6066\teval-mlogloss:1.62739\n",
      "[11]\ttrain-mlogloss:1.5655\teval-mlogloss:1.58649\n",
      "[12]\ttrain-mlogloss:1.52853\teval-mlogloss:1.54982\n",
      "[13]\ttrain-mlogloss:1.49494\teval-mlogloss:1.51686\n",
      "[14]\ttrain-mlogloss:1.46337\teval-mlogloss:1.48535\n",
      "[15]\ttrain-mlogloss:1.43535\teval-mlogloss:1.45758\n",
      "[16]\ttrain-mlogloss:1.41014\teval-mlogloss:1.43251\n",
      "[17]\ttrain-mlogloss:1.38587\teval-mlogloss:1.4085\n",
      "[18]\ttrain-mlogloss:1.36393\teval-mlogloss:1.3866\n",
      "[19]\ttrain-mlogloss:1.34367\teval-mlogloss:1.36631\n",
      "[20]\ttrain-mlogloss:1.32573\teval-mlogloss:1.34903\n",
      "[21]\ttrain-mlogloss:1.30889\teval-mlogloss:1.33252\n",
      "[22]\ttrain-mlogloss:1.29315\teval-mlogloss:1.31707\n",
      "[23]\ttrain-mlogloss:1.27918\teval-mlogloss:1.30339\n",
      "[24]\ttrain-mlogloss:1.26575\teval-mlogloss:1.28989\n",
      "[25]\ttrain-mlogloss:1.2533\teval-mlogloss:1.27782\n",
      "[26]\ttrain-mlogloss:1.24179\teval-mlogloss:1.26643\n",
      "[27]\ttrain-mlogloss:1.23168\teval-mlogloss:1.25677\n",
      "[28]\ttrain-mlogloss:1.22143\teval-mlogloss:1.24676\n",
      "[29]\ttrain-mlogloss:1.21202\teval-mlogloss:1.23751\n",
      "[30]\ttrain-mlogloss:1.20364\teval-mlogloss:1.22952\n",
      "[31]\ttrain-mlogloss:1.19508\teval-mlogloss:1.22138\n",
      "[32]\ttrain-mlogloss:1.18736\teval-mlogloss:1.21404\n",
      "[33]\ttrain-mlogloss:1.1799\teval-mlogloss:1.20684\n",
      "[34]\ttrain-mlogloss:1.17291\teval-mlogloss:1.2002\n",
      "[35]\ttrain-mlogloss:1.16642\teval-mlogloss:1.19424\n",
      "[36]\ttrain-mlogloss:1.16024\teval-mlogloss:1.18842\n",
      "[37]\ttrain-mlogloss:1.15452\teval-mlogloss:1.18315\n",
      "[38]\ttrain-mlogloss:1.14888\teval-mlogloss:1.17794\n",
      "[39]\ttrain-mlogloss:1.14383\teval-mlogloss:1.17324\n",
      "[40]\ttrain-mlogloss:1.13897\teval-mlogloss:1.16898\n",
      "[41]\ttrain-mlogloss:1.13448\teval-mlogloss:1.16502\n",
      "[42]\ttrain-mlogloss:1.13017\teval-mlogloss:1.16111\n",
      "[43]\ttrain-mlogloss:1.12624\teval-mlogloss:1.15759\n",
      "[44]\ttrain-mlogloss:1.12238\teval-mlogloss:1.15414\n",
      "[45]\ttrain-mlogloss:1.11864\teval-mlogloss:1.15076\n",
      "[46]\ttrain-mlogloss:1.11501\teval-mlogloss:1.14769\n",
      "[47]\ttrain-mlogloss:1.11152\teval-mlogloss:1.14455\n",
      "[48]\ttrain-mlogloss:1.10833\teval-mlogloss:1.14189\n",
      "[49]\ttrain-mlogloss:1.1053\teval-mlogloss:1.13923\n",
      "[50]\ttrain-mlogloss:1.1023\teval-mlogloss:1.13669\n",
      "[51]\ttrain-mlogloss:1.09945\teval-mlogloss:1.1343\n",
      "[52]\ttrain-mlogloss:1.09691\teval-mlogloss:1.13211\n",
      "[53]\ttrain-mlogloss:1.09436\teval-mlogloss:1.13005\n",
      "[54]\ttrain-mlogloss:1.09173\teval-mlogloss:1.12798\n",
      "[55]\ttrain-mlogloss:1.08939\teval-mlogloss:1.12599\n",
      "[56]\ttrain-mlogloss:1.08709\teval-mlogloss:1.12411\n",
      "[57]\ttrain-mlogloss:1.08493\teval-mlogloss:1.12234\n",
      "[58]\ttrain-mlogloss:1.08285\teval-mlogloss:1.12068\n",
      "[59]\ttrain-mlogloss:1.08093\teval-mlogloss:1.11925\n",
      "[60]\ttrain-mlogloss:1.0789\teval-mlogloss:1.11771\n",
      "[61]\ttrain-mlogloss:1.07706\teval-mlogloss:1.11635\n",
      "[62]\ttrain-mlogloss:1.0754\teval-mlogloss:1.11498\n",
      "[63]\ttrain-mlogloss:1.07368\teval-mlogloss:1.11377\n",
      "[64]\ttrain-mlogloss:1.07208\teval-mlogloss:1.11257\n",
      "[65]\ttrain-mlogloss:1.07043\teval-mlogloss:1.11153\n",
      "[66]\ttrain-mlogloss:1.06902\teval-mlogloss:1.11045\n",
      "[67]\ttrain-mlogloss:1.0676\teval-mlogloss:1.10947\n",
      "[68]\ttrain-mlogloss:1.06611\teval-mlogloss:1.10847\n",
      "[69]\ttrain-mlogloss:1.06476\teval-mlogloss:1.10761\n",
      "[70]\ttrain-mlogloss:1.06343\teval-mlogloss:1.10671\n",
      "[71]\ttrain-mlogloss:1.06212\teval-mlogloss:1.1058\n",
      "[72]\ttrain-mlogloss:1.06085\teval-mlogloss:1.105\n",
      "[73]\ttrain-mlogloss:1.05961\teval-mlogloss:1.10426\n",
      "[74]\ttrain-mlogloss:1.05841\teval-mlogloss:1.10355\n",
      "[75]\ttrain-mlogloss:1.05727\teval-mlogloss:1.10288\n",
      "[76]\ttrain-mlogloss:1.05621\teval-mlogloss:1.10229\n",
      "[77]\ttrain-mlogloss:1.05503\teval-mlogloss:1.10159\n",
      "[78]\ttrain-mlogloss:1.05403\teval-mlogloss:1.10104\n",
      "[79]\ttrain-mlogloss:1.05312\teval-mlogloss:1.10046\n",
      "[80]\ttrain-mlogloss:1.05222\teval-mlogloss:1.09996\n",
      "[81]\ttrain-mlogloss:1.05112\teval-mlogloss:1.09927\n",
      "[82]\ttrain-mlogloss:1.05034\teval-mlogloss:1.09879\n",
      "[83]\ttrain-mlogloss:1.04947\teval-mlogloss:1.09831\n",
      "[84]\ttrain-mlogloss:1.04846\teval-mlogloss:1.09781\n",
      "[85]\ttrain-mlogloss:1.04761\teval-mlogloss:1.09739\n",
      "[86]\ttrain-mlogloss:1.04667\teval-mlogloss:1.09693\n",
      "[87]\ttrain-mlogloss:1.04591\teval-mlogloss:1.09653\n",
      "[88]\ttrain-mlogloss:1.04511\teval-mlogloss:1.09618\n",
      "[89]\ttrain-mlogloss:1.04432\teval-mlogloss:1.09583\n",
      "[90]\ttrain-mlogloss:1.04366\teval-mlogloss:1.09555\n",
      "[91]\ttrain-mlogloss:1.04294\teval-mlogloss:1.09523\n",
      "[92]\ttrain-mlogloss:1.04209\teval-mlogloss:1.09493\n",
      "[93]\ttrain-mlogloss:1.04133\teval-mlogloss:1.09463\n",
      "[94]\ttrain-mlogloss:1.04048\teval-mlogloss:1.0943\n",
      "[95]\ttrain-mlogloss:1.03974\teval-mlogloss:1.09408\n",
      "[96]\ttrain-mlogloss:1.03913\teval-mlogloss:1.09381\n",
      "[97]\ttrain-mlogloss:1.0384\teval-mlogloss:1.09358\n",
      "[98]\ttrain-mlogloss:1.03782\teval-mlogloss:1.09333\n",
      "[99]\ttrain-mlogloss:1.03721\teval-mlogloss:1.09308\n",
      "[100]\ttrain-mlogloss:1.03663\teval-mlogloss:1.09286\n",
      "[101]\ttrain-mlogloss:1.0358\teval-mlogloss:1.09261\n",
      "[102]\ttrain-mlogloss:1.03518\teval-mlogloss:1.09246\n",
      "[103]\ttrain-mlogloss:1.03459\teval-mlogloss:1.09225\n",
      "[104]\ttrain-mlogloss:1.03398\teval-mlogloss:1.0921\n",
      "[105]\ttrain-mlogloss:1.03306\teval-mlogloss:1.09185\n",
      "[106]\ttrain-mlogloss:1.03249\teval-mlogloss:1.09166\n",
      "[107]\ttrain-mlogloss:1.03184\teval-mlogloss:1.09146\n",
      "[108]\ttrain-mlogloss:1.03118\teval-mlogloss:1.09123\n",
      "[109]\ttrain-mlogloss:1.03054\teval-mlogloss:1.09104\n",
      "[110]\ttrain-mlogloss:1.02997\teval-mlogloss:1.09086\n",
      "[111]\ttrain-mlogloss:1.02928\teval-mlogloss:1.09065\n",
      "[112]\ttrain-mlogloss:1.02869\teval-mlogloss:1.09043\n",
      "[113]\ttrain-mlogloss:1.02811\teval-mlogloss:1.09028\n",
      "[114]\ttrain-mlogloss:1.02748\teval-mlogloss:1.09007\n",
      "[115]\ttrain-mlogloss:1.02686\teval-mlogloss:1.08989\n",
      "[116]\ttrain-mlogloss:1.02626\teval-mlogloss:1.08971\n",
      "[117]\ttrain-mlogloss:1.02571\teval-mlogloss:1.08958\n",
      "[118]\ttrain-mlogloss:1.02497\teval-mlogloss:1.08946\n",
      "[119]\ttrain-mlogloss:1.02451\teval-mlogloss:1.08934\n",
      "[120]\ttrain-mlogloss:1.02395\teval-mlogloss:1.08926\n",
      "[121]\ttrain-mlogloss:1.02341\teval-mlogloss:1.08918\n",
      "[122]\ttrain-mlogloss:1.02286\teval-mlogloss:1.08908\n",
      "[123]\ttrain-mlogloss:1.02224\teval-mlogloss:1.08902\n",
      "[124]\ttrain-mlogloss:1.02163\teval-mlogloss:1.08892\n",
      "[125]\ttrain-mlogloss:1.02104\teval-mlogloss:1.08876\n",
      "[126]\ttrain-mlogloss:1.02062\teval-mlogloss:1.08871\n",
      "[127]\ttrain-mlogloss:1.02005\teval-mlogloss:1.08856\n",
      "[128]\ttrain-mlogloss:1.01942\teval-mlogloss:1.08847\n",
      "[129]\ttrain-mlogloss:1.01881\teval-mlogloss:1.08838\n",
      "[130]\ttrain-mlogloss:1.01827\teval-mlogloss:1.08833\n",
      "[131]\ttrain-mlogloss:1.01752\teval-mlogloss:1.08824\n",
      "[132]\ttrain-mlogloss:1.0169\teval-mlogloss:1.08818\n",
      "[133]\ttrain-mlogloss:1.01626\teval-mlogloss:1.08809\n",
      "[134]\ttrain-mlogloss:1.01562\teval-mlogloss:1.088\n",
      "[135]\ttrain-mlogloss:1.01513\teval-mlogloss:1.08793\n",
      "[136]\ttrain-mlogloss:1.0146\teval-mlogloss:1.08788\n",
      "[137]\ttrain-mlogloss:1.01394\teval-mlogloss:1.08777\n",
      "[138]\ttrain-mlogloss:1.01353\teval-mlogloss:1.08768\n",
      "[139]\ttrain-mlogloss:1.01295\teval-mlogloss:1.08768\n",
      "[140]\ttrain-mlogloss:1.01221\teval-mlogloss:1.08759\n",
      "[141]\ttrain-mlogloss:1.01172\teval-mlogloss:1.0875\n",
      "[142]\ttrain-mlogloss:1.01106\teval-mlogloss:1.08743\n",
      "[143]\ttrain-mlogloss:1.01048\teval-mlogloss:1.08743\n",
      "[144]\ttrain-mlogloss:1.01\teval-mlogloss:1.08738\n",
      "[145]\ttrain-mlogloss:1.00936\teval-mlogloss:1.08735\n",
      "[146]\ttrain-mlogloss:1.00882\teval-mlogloss:1.0873\n",
      "[147]\ttrain-mlogloss:1.00817\teval-mlogloss:1.08726\n",
      "[148]\ttrain-mlogloss:1.00764\teval-mlogloss:1.08718\n",
      "[149]\ttrain-mlogloss:1.00711\teval-mlogloss:1.08719\n",
      "[150]\ttrain-mlogloss:1.00648\teval-mlogloss:1.08712\n",
      "[151]\ttrain-mlogloss:1.00592\teval-mlogloss:1.08708\n",
      "[152]\ttrain-mlogloss:1.00524\teval-mlogloss:1.08703\n",
      "[153]\ttrain-mlogloss:1.00468\teval-mlogloss:1.08698\n",
      "[154]\ttrain-mlogloss:1.00426\teval-mlogloss:1.08702\n",
      "[155]\ttrain-mlogloss:1.0036\teval-mlogloss:1.08698\n",
      "[156]\ttrain-mlogloss:1.00313\teval-mlogloss:1.08694\n",
      "[157]\ttrain-mlogloss:1.0027\teval-mlogloss:1.08693\n",
      "[158]\ttrain-mlogloss:1.00211\teval-mlogloss:1.08689\n",
      "[159]\ttrain-mlogloss:1.00144\teval-mlogloss:1.08691\n",
      "[160]\ttrain-mlogloss:1.00067\teval-mlogloss:1.08682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161]\ttrain-mlogloss:1.00006\teval-mlogloss:1.08678\n",
      "[162]\ttrain-mlogloss:0.999429\teval-mlogloss:1.08679\n",
      "[163]\ttrain-mlogloss:0.998887\teval-mlogloss:1.08677\n",
      "[164]\ttrain-mlogloss:0.998346\teval-mlogloss:1.08673\n",
      "[165]\ttrain-mlogloss:0.99781\teval-mlogloss:1.0867\n",
      "[166]\ttrain-mlogloss:0.997108\teval-mlogloss:1.08671\n",
      "[167]\ttrain-mlogloss:0.996648\teval-mlogloss:1.08668\n",
      "[168]\ttrain-mlogloss:0.99608\teval-mlogloss:1.08669\n",
      "[169]\ttrain-mlogloss:0.995433\teval-mlogloss:1.08671\n",
      "[170]\ttrain-mlogloss:0.994798\teval-mlogloss:1.08664\n",
      "[171]\ttrain-mlogloss:0.994195\teval-mlogloss:1.08659\n",
      "[172]\ttrain-mlogloss:0.993533\teval-mlogloss:1.08658\n",
      "[173]\ttrain-mlogloss:0.992856\teval-mlogloss:1.08663\n",
      "[174]\ttrain-mlogloss:0.992266\teval-mlogloss:1.08662\n",
      "[175]\ttrain-mlogloss:0.991827\teval-mlogloss:1.08663\n",
      "[176]\ttrain-mlogloss:0.99135\teval-mlogloss:1.08667\n",
      "[177]\ttrain-mlogloss:0.990783\teval-mlogloss:1.08668\n",
      "[178]\ttrain-mlogloss:0.990165\teval-mlogloss:1.08656\n",
      "[179]\ttrain-mlogloss:0.989727\teval-mlogloss:1.08653\n",
      "[180]\ttrain-mlogloss:0.989258\teval-mlogloss:1.08655\n",
      "[181]\ttrain-mlogloss:0.988687\teval-mlogloss:1.08646\n",
      "[182]\ttrain-mlogloss:0.988187\teval-mlogloss:1.08644\n",
      "[183]\ttrain-mlogloss:0.987505\teval-mlogloss:1.08649\n",
      "[184]\ttrain-mlogloss:0.987062\teval-mlogloss:1.08649\n",
      "[185]\ttrain-mlogloss:0.986466\teval-mlogloss:1.08653\n",
      "[186]\ttrain-mlogloss:0.986\teval-mlogloss:1.08653\n",
      "[187]\ttrain-mlogloss:0.985563\teval-mlogloss:1.08654\n",
      "[188]\ttrain-mlogloss:0.985121\teval-mlogloss:1.08653\n",
      "[189]\ttrain-mlogloss:0.984568\teval-mlogloss:1.08661\n",
      "[190]\ttrain-mlogloss:0.984085\teval-mlogloss:1.08666\n",
      "[191]\ttrain-mlogloss:0.983502\teval-mlogloss:1.08665\n",
      "[192]\ttrain-mlogloss:0.982953\teval-mlogloss:1.08662\n",
      "[193]\ttrain-mlogloss:0.982299\teval-mlogloss:1.08661\n",
      "[194]\ttrain-mlogloss:0.981866\teval-mlogloss:1.08659\n",
      "[195]\ttrain-mlogloss:0.981434\teval-mlogloss:1.08663\n",
      "[196]\ttrain-mlogloss:0.980874\teval-mlogloss:1.08659\n",
      "[197]\ttrain-mlogloss:0.980209\teval-mlogloss:1.08663\n",
      "[198]\ttrain-mlogloss:0.979668\teval-mlogloss:1.08661\n",
      "[199]\ttrain-mlogloss:0.979127\teval-mlogloss:1.08659\n",
      "[200]\ttrain-mlogloss:0.978581\teval-mlogloss:1.08657\n",
      "[201]\ttrain-mlogloss:0.978129\teval-mlogloss:1.08661\n",
      "[202]\ttrain-mlogloss:0.977725\teval-mlogloss:1.08662\n",
      "Stopping. Best iteration:\n",
      "[182]\ttrain-mlogloss:0.988187\teval-mlogloss:1.08644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watch_list = [(dtrn, 'train'), (dvld, 'eval')]\n",
    "model = xgb.train(param, dtrn, num_boost_round=1000, evals=watch_list, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open(\"model/xgb.baseline.pkl\", \"wb\"))\n",
    "best_ntree_limit = model.best_ntree_limit\n",
    "best_ntree_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapk import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "vld = trn[trn['fecha_dato'] == vld_date]\n",
    "ncodpers_vld = vld.as_matrix(columns=['ncodpers'])\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    padd = prod + '_add'\n",
    "    vld[padd] = vld[prod] - vld[prev]\n",
    "    \n",
    "add_vld = vld.as_matrix(columns=[prod + '_add' for prod in prods])\n",
    "add_vld_list = [list() for i in range(len(ncodpers_vld))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vld = 0\n",
    "for ncodper in range(len(ncodpers_vld)):\n",
    "    for prod in range(len(prods)):\n",
    "        if add_vld[ncodper, prod] > 0:\n",
    "            add_vld_list[ncodper].append(prod)\n",
    "            count_vld += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0427229053992809\n"
     ]
    }
   ],
   "source": [
    "print(mapk(add_vld_list, add_vld_list, 7, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_vld = vld.as_matrix(columns=features)\n",
    "Y_vld = vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
    "preds_vld = model.predict(dvld, ntree_limit=best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# dead_vld = vld['indfall'] == 'S'\n",
    "preds_vld = preds_vld - vld.as_matrix(columns=[prod + '_prev' for prod in prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_vld = []\n",
    "for ncodper, pred in zip(ncodpers_vld, preds_vld):\n",
    "    y_prods = [(y, p, ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    result_vld.append([ip for y,p,ip in y_prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036512075033758036\n"
     ]
    }
   ],
   "source": [
    "print(mapk(add_vld_list, result_vld, 7, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Total Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_all = XY.as_matrix(columns=features)\n",
    "Y_all = XY.as_matrix(columns=['y'])\n",
    "dall = xgb.DMatrix(X_all, label=Y_all, feature_names=features)\n",
    "watch_list = [(dall, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "183\n",
      "[0]\ttrain-mlogloss:2.66395\n",
      "[1]\ttrain-mlogloss:2.42069\n",
      "[2]\ttrain-mlogloss:2.24519\n",
      "[3]\ttrain-mlogloss:2.11257\n",
      "[4]\ttrain-mlogloss:2.0014\n",
      "[5]\ttrain-mlogloss:1.91305\n",
      "[6]\ttrain-mlogloss:1.83521\n",
      "[7]\ttrain-mlogloss:1.7656\n",
      "[8]\ttrain-mlogloss:1.70444\n",
      "[9]\ttrain-mlogloss:1.65411\n",
      "[10]\ttrain-mlogloss:1.60595\n",
      "[11]\ttrain-mlogloss:1.56478\n",
      "[12]\ttrain-mlogloss:1.52775\n",
      "[13]\ttrain-mlogloss:1.49413\n",
      "[14]\ttrain-mlogloss:1.46249\n",
      "[15]\ttrain-mlogloss:1.43445\n",
      "[16]\ttrain-mlogloss:1.4093\n",
      "[17]\ttrain-mlogloss:1.38497\n",
      "[18]\ttrain-mlogloss:1.36309\n",
      "[19]\ttrain-mlogloss:1.3428\n",
      "[20]\ttrain-mlogloss:1.32489\n",
      "[21]\ttrain-mlogloss:1.30815\n",
      "[22]\ttrain-mlogloss:1.2926\n",
      "[23]\ttrain-mlogloss:1.27868\n",
      "[24]\ttrain-mlogloss:1.26527\n",
      "[25]\ttrain-mlogloss:1.25289\n",
      "[26]\ttrain-mlogloss:1.24134\n",
      "[27]\ttrain-mlogloss:1.23123\n",
      "[28]\ttrain-mlogloss:1.22088\n",
      "[29]\ttrain-mlogloss:1.2114\n",
      "[30]\ttrain-mlogloss:1.20293\n",
      "[31]\ttrain-mlogloss:1.19458\n",
      "[32]\ttrain-mlogloss:1.18694\n",
      "[33]\ttrain-mlogloss:1.17944\n",
      "[34]\ttrain-mlogloss:1.17256\n",
      "[35]\ttrain-mlogloss:1.16606\n",
      "[36]\ttrain-mlogloss:1.16\n",
      "[37]\ttrain-mlogloss:1.15436\n",
      "[38]\ttrain-mlogloss:1.14882\n",
      "[39]\ttrain-mlogloss:1.14382\n",
      "[40]\ttrain-mlogloss:1.13907\n",
      "[41]\ttrain-mlogloss:1.13465\n",
      "[42]\ttrain-mlogloss:1.13035\n",
      "[43]\ttrain-mlogloss:1.12655\n",
      "[44]\ttrain-mlogloss:1.12275\n",
      "[45]\ttrain-mlogloss:1.11904\n",
      "[46]\ttrain-mlogloss:1.11557\n",
      "[47]\ttrain-mlogloss:1.11214\n",
      "[48]\ttrain-mlogloss:1.109\n",
      "[49]\ttrain-mlogloss:1.10598\n",
      "[50]\ttrain-mlogloss:1.10305\n",
      "[51]\ttrain-mlogloss:1.10015\n",
      "[52]\ttrain-mlogloss:1.09769\n",
      "[53]\ttrain-mlogloss:1.09519\n",
      "[54]\ttrain-mlogloss:1.09267\n",
      "[55]\ttrain-mlogloss:1.09049\n",
      "[56]\ttrain-mlogloss:1.08826\n",
      "[57]\ttrain-mlogloss:1.08615\n",
      "[58]\ttrain-mlogloss:1.08415\n",
      "[59]\ttrain-mlogloss:1.08226\n",
      "[60]\ttrain-mlogloss:1.08041\n",
      "[61]\ttrain-mlogloss:1.07859\n",
      "[62]\ttrain-mlogloss:1.07693\n",
      "[63]\ttrain-mlogloss:1.07534\n",
      "[64]\ttrain-mlogloss:1.07374\n",
      "[65]\ttrain-mlogloss:1.07215\n",
      "[66]\ttrain-mlogloss:1.07076\n",
      "[67]\ttrain-mlogloss:1.06932\n",
      "[68]\ttrain-mlogloss:1.06799\n",
      "[69]\ttrain-mlogloss:1.06668\n",
      "[70]\ttrain-mlogloss:1.06532\n",
      "[71]\ttrain-mlogloss:1.06404\n",
      "[72]\ttrain-mlogloss:1.06284\n",
      "[73]\ttrain-mlogloss:1.06166\n",
      "[74]\ttrain-mlogloss:1.06063\n",
      "[75]\ttrain-mlogloss:1.05958\n",
      "[76]\ttrain-mlogloss:1.05853\n",
      "[77]\ttrain-mlogloss:1.05748\n",
      "[78]\ttrain-mlogloss:1.05647\n",
      "[79]\ttrain-mlogloss:1.05557\n",
      "[80]\ttrain-mlogloss:1.05466\n",
      "[81]\ttrain-mlogloss:1.05373\n",
      "[82]\ttrain-mlogloss:1.05293\n",
      "[83]\ttrain-mlogloss:1.05212\n",
      "[84]\ttrain-mlogloss:1.05122\n",
      "[85]\ttrain-mlogloss:1.05044\n",
      "[86]\ttrain-mlogloss:1.04951\n",
      "[87]\ttrain-mlogloss:1.04872\n",
      "[88]\ttrain-mlogloss:1.04798\n",
      "[89]\ttrain-mlogloss:1.04717\n",
      "[90]\ttrain-mlogloss:1.0465\n",
      "[91]\ttrain-mlogloss:1.04579\n",
      "[92]\ttrain-mlogloss:1.04505\n",
      "[93]\ttrain-mlogloss:1.04448\n",
      "[94]\ttrain-mlogloss:1.04379\n",
      "[95]\ttrain-mlogloss:1.04309\n",
      "[96]\ttrain-mlogloss:1.04237\n",
      "[97]\ttrain-mlogloss:1.04171\n",
      "[98]\ttrain-mlogloss:1.04117\n",
      "[99]\ttrain-mlogloss:1.04059\n",
      "[100]\ttrain-mlogloss:1.03991\n",
      "[101]\ttrain-mlogloss:1.03915\n",
      "[102]\ttrain-mlogloss:1.03857\n",
      "[103]\ttrain-mlogloss:1.03795\n",
      "[104]\ttrain-mlogloss:1.0374\n",
      "[105]\ttrain-mlogloss:1.03677\n",
      "[106]\ttrain-mlogloss:1.0362\n",
      "[107]\ttrain-mlogloss:1.0356\n",
      "[108]\ttrain-mlogloss:1.03512\n",
      "[109]\ttrain-mlogloss:1.03458\n",
      "[110]\ttrain-mlogloss:1.03409\n",
      "[111]\ttrain-mlogloss:1.03344\n",
      "[112]\ttrain-mlogloss:1.03293\n",
      "[113]\ttrain-mlogloss:1.03238\n",
      "[114]\ttrain-mlogloss:1.03192\n",
      "[115]\ttrain-mlogloss:1.03141\n",
      "[116]\ttrain-mlogloss:1.03086\n",
      "[117]\ttrain-mlogloss:1.03031\n",
      "[118]\ttrain-mlogloss:1.02988\n",
      "[119]\ttrain-mlogloss:1.02938\n",
      "[120]\ttrain-mlogloss:1.02896\n",
      "[121]\ttrain-mlogloss:1.02834\n",
      "[122]\ttrain-mlogloss:1.0279\n",
      "[123]\ttrain-mlogloss:1.02742\n",
      "[124]\ttrain-mlogloss:1.02688\n",
      "[125]\ttrain-mlogloss:1.02628\n",
      "[126]\ttrain-mlogloss:1.02579\n",
      "[127]\ttrain-mlogloss:1.02537\n",
      "[128]\ttrain-mlogloss:1.02482\n",
      "[129]\ttrain-mlogloss:1.02433\n",
      "[130]\ttrain-mlogloss:1.02376\n",
      "[131]\ttrain-mlogloss:1.02323\n",
      "[132]\ttrain-mlogloss:1.02276\n",
      "[133]\ttrain-mlogloss:1.02226\n",
      "[134]\ttrain-mlogloss:1.02185\n",
      "[135]\ttrain-mlogloss:1.02123\n",
      "[136]\ttrain-mlogloss:1.02064\n",
      "[137]\ttrain-mlogloss:1.02002\n",
      "[138]\ttrain-mlogloss:1.01958\n",
      "[139]\ttrain-mlogloss:1.01913\n",
      "[140]\ttrain-mlogloss:1.01858\n",
      "[141]\ttrain-mlogloss:1.0181\n",
      "[142]\ttrain-mlogloss:1.01739\n",
      "[143]\ttrain-mlogloss:1.01686\n",
      "[144]\ttrain-mlogloss:1.01638\n",
      "[145]\ttrain-mlogloss:1.01584\n",
      "[146]\ttrain-mlogloss:1.01539\n",
      "[147]\ttrain-mlogloss:1.0148\n",
      "[148]\ttrain-mlogloss:1.01438\n",
      "[149]\ttrain-mlogloss:1.01389\n",
      "[150]\ttrain-mlogloss:1.01335\n",
      "[151]\ttrain-mlogloss:1.01293\n",
      "[152]\ttrain-mlogloss:1.01248\n",
      "[153]\ttrain-mlogloss:1.01198\n",
      "[154]\ttrain-mlogloss:1.01142\n",
      "[155]\ttrain-mlogloss:1.01099\n",
      "[156]\ttrain-mlogloss:1.01058\n",
      "[157]\ttrain-mlogloss:1.01019\n",
      "[158]\ttrain-mlogloss:1.00964\n",
      "[159]\ttrain-mlogloss:1.00907\n",
      "[160]\ttrain-mlogloss:1.00858\n",
      "[161]\ttrain-mlogloss:1.00806\n",
      "[162]\ttrain-mlogloss:1.00763\n",
      "[163]\ttrain-mlogloss:1.00716\n",
      "[164]\ttrain-mlogloss:1.00668\n",
      "[165]\ttrain-mlogloss:1.00632\n",
      "[166]\ttrain-mlogloss:1.00572\n",
      "[167]\ttrain-mlogloss:1.00526\n",
      "[168]\ttrain-mlogloss:1.00475\n",
      "[169]\ttrain-mlogloss:1.00414\n",
      "[170]\ttrain-mlogloss:1.00371\n",
      "[171]\ttrain-mlogloss:1.00327\n",
      "[172]\ttrain-mlogloss:1.00275\n",
      "[173]\ttrain-mlogloss:1.00236\n",
      "[174]\ttrain-mlogloss:1.00185\n",
      "[175]\ttrain-mlogloss:1.00131\n",
      "[176]\ttrain-mlogloss:1.00085\n",
      "[177]\ttrain-mlogloss:1.00031\n",
      "[178]\ttrain-mlogloss:0.999832\n",
      "[179]\ttrain-mlogloss:0.999405\n",
      "[180]\ttrain-mlogloss:0.998892\n",
      "[181]\ttrain-mlogloss:0.998271\n",
      "[182]\ttrain-mlogloss:0.997923\n",
      "[183]\ttrain-mlogloss:0.997409\n",
      "[184]\ttrain-mlogloss:0.996844\n",
      "[185]\ttrain-mlogloss:0.996313\n",
      "[186]\ttrain-mlogloss:0.99589\n",
      "[187]\ttrain-mlogloss:0.995316\n",
      "[188]\ttrain-mlogloss:0.994809\n",
      "[189]\ttrain-mlogloss:0.994222\n",
      "[190]\ttrain-mlogloss:0.993651\n",
      "[191]\ttrain-mlogloss:0.993122\n",
      "[192]\ttrain-mlogloss:0.992477\n",
      "[193]\ttrain-mlogloss:0.99189\n",
      "[194]\ttrain-mlogloss:0.991429\n",
      "[195]\ttrain-mlogloss:0.990981\n",
      "[196]\ttrain-mlogloss:0.99054\n",
      "[197]\ttrain-mlogloss:0.989964\n",
      "[198]\ttrain-mlogloss:0.989474\n",
      "[199]\ttrain-mlogloss:0.988836\n",
      "[200]\ttrain-mlogloss:0.988225\n",
      "[201]\ttrain-mlogloss:0.987872\n",
      "[202]\ttrain-mlogloss:0.987502\n",
      "[203]\ttrain-mlogloss:0.987108\n",
      "[204]\ttrain-mlogloss:0.986706\n",
      "[205]\ttrain-mlogloss:0.98636\n",
      "[206]\ttrain-mlogloss:0.985957\n",
      "[207]\ttrain-mlogloss:0.985587\n",
      "[208]\ttrain-mlogloss:0.985018\n",
      "[209]\ttrain-mlogloss:0.984433\n",
      "[210]\ttrain-mlogloss:0.983923\n",
      "[211]\ttrain-mlogloss:0.983453\n",
      "[212]\ttrain-mlogloss:0.98299\n",
      "[213]\ttrain-mlogloss:0.982488\n",
      "[214]\ttrain-mlogloss:0.982032\n",
      "[215]\ttrain-mlogloss:0.981646\n",
      "[216]\ttrain-mlogloss:0.981213\n",
      "[217]\ttrain-mlogloss:0.980801\n",
      "[218]\ttrain-mlogloss:0.980228\n",
      "[219]\ttrain-mlogloss:0.979728\n",
      "[220]\ttrain-mlogloss:0.979304\n",
      "[221]\ttrain-mlogloss:0.97893\n",
      "[222]\ttrain-mlogloss:0.97844\n",
      "[223]\ttrain-mlogloss:0.978029\n",
      "[224]\ttrain-mlogloss:0.977591\n",
      "[225]\ttrain-mlogloss:0.977254\n"
     ]
    }
   ],
   "source": [
    "best_ntree_limit = int(best_ntree_limit * (len(XY_trn) + len(XY_vld)) / len(XY_trn))\n",
    "print(best_ntree_limit)\n",
    "print(model.best_ntree_limit)\n",
    "model = xgb.train(param, dall, num_boost_round=best_ntree_limit, evals=watch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance:\n",
      "('renta', 19116)\n",
      "('age', 18070)\n",
      "('antiguedad', 16904)\n",
      "('age_prev', 12179)\n",
      "('antiguedad_prev', 12152)\n",
      "('fecha_alta_month', 11207)\n",
      "('nomprov', 10988)\n",
      "('fecha_alta_year', 9065)\n",
      "('renta_prev', 7870)\n",
      "('canal_entrada', 7364)\n",
      "('nomprov_prev', 5923)\n",
      "('canal_entrada_prev', 4332)\n",
      "('fecha_alta_month_prev', 4071)\n",
      "('ind_recibo_ult1_prev', 3248)\n",
      "('sexo', 3169)\n",
      "('ind_ecue_fin_ult1_prev', 3119)\n",
      "('fecha_alta_year_prev', 2991)\n",
      "('ind_cco_fin_ult1_prev', 2845)\n",
      "('ind_cno_fin_ult1_prev', 2633)\n",
      "('segmento', 2225)\n",
      "('ind_tjcr_fin_ult1_prev', 2084)\n",
      "('ind_reca_fin_ult1_prev', 2054)\n",
      "('segmento_prev', 1899)\n",
      "('ind_nom_pens_ult1_prev', 1606)\n",
      "('ind_valo_fin_ult1_prev', 1567)\n",
      "('tiprel_1mes', 1556)\n",
      "('ind_nomina_ult1_prev', 1509)\n",
      "('ind_dela_fin_ult1_prev', 1450)\n",
      "('ind_ctop_fin_ult1_prev', 1444)\n",
      "('ind_actividad_cliente', 1310)\n",
      "('sexo_prev', 1249)\n",
      "('tiprel_1mes_prev', 1132)\n",
      "('ind_ctpp_fin_ult1_prev', 1118)\n",
      "('ind_fond_fin_ult1_prev', 1016)\n",
      "('ind_ctma_fin_ult1_prev', 868)\n",
      "('ind_actividad_cliente_prev', 863)\n",
      "('indext', 747)\n",
      "('ind_nuevo', 700)\n",
      "('ind_plan_fin_ult1_prev', 611)\n",
      "('ind_hip_fin_ult1_prev', 497)\n",
      "('ind_deco_fin_ult1_prev', 388)\n",
      "('indext_prev', 383)\n",
      "('indrel_1mes', 368)\n",
      "('ind_nuevo_prev', 364)\n",
      "('pais_residencia', 190)\n",
      "('ind_empleado_prev', 168)\n",
      "('indrel_1mes_prev', 164)\n",
      "('ind_viv_fin_ult1_prev', 147)\n",
      "('indrel', 143)\n",
      "('ind_empleado', 129)\n",
      "('pais_residencia_prev', 114)\n",
      "('ind_deme_fin_ult1_prev', 108)\n",
      "('ind_ctju_fin_ult1_prev', 87)\n",
      "('ind_pres_fin_ult1_prev', 70)\n",
      "('ult_fec_cli_1t_month', 59)\n",
      "('ind_cder_fin_ult1_prev', 36)\n",
      "('conyuemp_prev', 21)\n",
      "('indresi', 13)\n",
      "('indresi_prev', 10)\n",
      "('ult_fec_cli_1t_year', 9)\n",
      "('conyuemp', 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importance:\")\n",
    "for kv in sorted([(k,v) for k,v in model.get_fscore().items()], key=lambda kv: kv[1], reverse=True):\n",
    "    print(kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_tst = tst.as_matrix(columns=features)\n",
    "dtst = xgb.DMatrix(X_tst, feature_names=features)\n",
    "preds_tst = model.predict(dtst, ntree_limit=best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\ProgramData\\Anaconda3\\envs\\dsc\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ncodpers_tst = tst.as_matrix(columns=['ncodpers'])\n",
    "preds_tst = preds_tst - tst.as_matrix(columns=[prod + '_prev' for prod in prods])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"model/xgb.baseline_total.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_vld = model.predict(dvld, ntree_limit=best_ntree_limit)\n",
    "preds_vld = preds_vld - vld.as_matrix(columns=[prod + '_prev' for prod in prods])\n",
    "result_vld = []\n",
    "for ncodper, pred in zip(ncodpers_vld, preds_vld):\n",
    "    y_prods = [(y, p, ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    result_vld.append([ip for y,p,ip in y_prods])\n",
    "print(mapk(add_vld_list, result_vld, 7, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file = open('model/xgb.baseline.2019-06-20_baseline2', 'w')\n",
    "submit_file.write('ncodpers,added_products\\n')\n",
    "count = 0\n",
    "for ncodper, pred in zip(ncodpers_tst, preds_tst):\n",
    "    y_prods = [(y,p,ip) for y, p, ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    y_prods = [p for y,p,ip in y_prods]\n",
    "    submit_file.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))\n",
    "submit_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
